ani_ids_na <- ani_ids == "anixxxx"
ani_ids[ani_ids_na] <- sample(1000:9999, size=sum(ani_ids_na), replace=F)
ani_ids[ani_ids_na] <- paste0("R", ani_ids[ani_ids_na])
data_info <- list(ani = ani_ids, gps = gps_units)
for(i in 1:length(data_files)) {
filestr <- gsub(paste0(dir_name,"(\\/)"), "", data_files[i])
site <- tolower(gsub("(\\_)(20)([0-9]{2}\\_)(.*\\_)(.*)(\\.csv)","", filestr))
df <- read.csv(data_files[i], skipNul = T)
aniid <- data_info$ani[i]
gpsid <- data_info$gps[i]
#on every 50th data file, increment file name counter and wipe data_sets
if(i %% 50 == 0 & i > 49) {
saveRDS(data_sets, rds_name)
num_saved_rds <- num_saved_rds + 1
rds_name <- paste0(data_dir, num_saved_rds, ".rds")
data_sets <- list()
}
# clean df
cleaned_df <- clean_df(df, aniid, gpsid)
# get meta from df
file_meta <- get_meta(df, i, data_files[i], site, aniid, rds_name)
# save meta to the designated meta df
meta_df <- save_meta(meta_df, file_meta)
# add cleaned df to the list of data
data_sets[[paste0("ani",aniid)]] <- cleaned_df
} #for loop
#save remaining data files
saveRDS(data_sets, rds_name)
return(meta_df)
}
clean_batch(list(name = "whatever", datapath = "data/to_process.zip"))
clean_batch(list(name = "whatever", datapath = file.path(getwd(), "data/to_process.zip"))
clean_batch(list(name = "whatever", datapath = file.path(getwd(), "data/to_process.zip") ) )
clean_batch(list(name = "whatever", datapath = file.path(getwd(), "data/to_process.zip") ) )
clean_batch <- function(data_dir) {
#initialize empty meta
meta_df <- data.frame(matrix(ncol = 9, nrow = 0))
meta_cols <- c("file_id", "file_name", "site", "ani_id", "min_date", "max_date", "min_lat", "max_lat", "storage")
colnames(meta_df) <- meta_cols
data_files <- unzip(data_dir$datapath, list=T)
data_files <- paste0(file.path(getwd(), "data/"),  data_files$Name)
data_sets <- list()
num_saved_rds <- 0
dir_name <- gsub(".zip", "", data_dir$name)
rds_name <- paste0(dir_name, ".rds")
gps_units <- gsub("(.*)(20)([0-9]{2}\\_)(.*)(\\_{1}.*)(\\.csv)","\\4",data_files)
ani_ids <- gsub("(.*)(20)([0-9]{2}\\_)(.*\\_)(.*)(\\.csv)","\\5",data_files)
# assign random ids to missing animal ids
ani_ids_na <- ani_ids == "anixxxx"
ani_ids[ani_ids_na] <- sample(1000:9999, size=sum(ani_ids_na), replace=F)
ani_ids[ani_ids_na] <- paste0("R", ani_ids[ani_ids_na])
data_info <- list(ani = ani_ids, gps = gps_units)
for(i in 1:length(data_files)) {
filestr <- gsub(paste0(dir_name,"(\\/)"), "", data_files[i])
site <- tolower(gsub("(\\_)(20)([0-9]{2}\\_)(.*\\_)(.*)(\\.csv)","", filestr))
df <- read.csv(data_files[i], skipNul = T)
aniid <- data_info$ani[i]
gpsid <- data_info$gps[i]
#on every 50th data file, increment file name counter and wipe data_sets
if(i %% 50 == 0 & i > 49) {
saveRDS(data_sets, rds_name)
num_saved_rds <- num_saved_rds + 1
rds_name <- paste0(data_dir, num_saved_rds, ".rds")
data_sets <- list()
}
# clean df
cleaned_df <- clean_df(df, aniid, gpsid)
# get meta from df
file_meta <- get_meta(df, i, data_files[i], site, aniid, rds_name)
# save meta to the designated meta df
meta_df <- save_meta(meta_df, file_meta)
# add cleaned df to the list of data
data_sets[[paste0("ani",aniid)]] <- cleaned_df
} #for loop
#save remaining data files
saveRDS(data_sets, rds_name)
return(meta_df)
}
clean_batch(list(name = "whatever", datapath = file.path(getwd(), "data/to_process.zip") ) )
clean_batch <- function(data_dir) {
#initialize empty meta
meta_df <- data.frame(matrix(ncol = 9, nrow = 0))
meta_cols <- c("file_id", "file_name", "site", "ani_id", "min_date", "max_date", "min_lat", "max_lat", "storage")
colnames(meta_df) <- meta_cols
data_files <- unzip(data_dir$datapath, list=T)
data_files <- paste0(file.path(getwd(), "data/"),  data_files$Name)
print(data_files)
data_sets <- list()
num_saved_rds <- 0
dir_name <- gsub(".zip", "", data_dir$name)
rds_name <- paste0(dir_name, ".rds")
gps_units <- gsub("(.*)(20)([0-9]{2}\\_)(.*)(\\_{1}.*)(\\.csv)","\\4",data_files)
ani_ids <- gsub("(.*)(20)([0-9]{2}\\_)(.*\\_)(.*)(\\.csv)","\\5",data_files)
# assign random ids to missing animal ids
ani_ids_na <- ani_ids == "anixxxx"
ani_ids[ani_ids_na] <- sample(1000:9999, size=sum(ani_ids_na), replace=F)
ani_ids[ani_ids_na] <- paste0("R", ani_ids[ani_ids_na])
data_info <- list(ani = ani_ids, gps = gps_units)
for(i in 1:length(data_files)) {
filestr <- gsub(paste0(dir_name,"(\\/)"), "", data_files[i])
site <- tolower(gsub("(\\_)(20)([0-9]{2}\\_)(.*\\_)(.*)(\\.csv)","", filestr))
df <- read.csv(data_files[i], skipNul = T)
aniid <- data_info$ani[i]
gpsid <- data_info$gps[i]
#on every 50th data file, increment file name counter and wipe data_sets
if(i %% 50 == 0 & i > 49) {
saveRDS(data_sets, rds_name)
num_saved_rds <- num_saved_rds + 1
rds_name <- paste0(data_dir, num_saved_rds, ".rds")
data_sets <- list()
}
# clean df
cleaned_df <- clean_df(df, aniid, gpsid)
# get meta from df
file_meta <- get_meta(df, i, data_files[i], site, aniid, rds_name)
# save meta to the designated meta df
meta_df <- save_meta(meta_df, file_meta)
# add cleaned df to the list of data
data_sets[[paste0("ani",aniid)]] <- cleaned_df
} #for loop
#save remaining data files
saveRDS(data_sets, rds_name)
return(meta_df)
}
clean_batch(list(name = "whatever", datapath = file.path(getwd(), "data/to_process.zip") ) )
clean_batch <- function(data_dir) {
#initialize empty meta
meta_df <- data.frame(matrix(ncol = 9, nrow = 0))
meta_cols <- c("file_id", "file_name", "site", "ani_id", "min_date", "max_date", "min_lat", "max_lat", "storage")
colnames(meta_df) <- meta_cols
data_files <- unzip(data_dir$datapath, list=T)
data_files <- paste0(getwd(), "/data/",  data_files$Name)
print(data_files)
data_sets <- list()
num_saved_rds <- 0
dir_name <- gsub(".zip", "", data_dir$name)
rds_name <- paste0(dir_name, ".rds")
gps_units <- gsub("(.*)(20)([0-9]{2}\\_)(.*)(\\_{1}.*)(\\.csv)","\\4",data_files)
ani_ids <- gsub("(.*)(20)([0-9]{2}\\_)(.*\\_)(.*)(\\.csv)","\\5",data_files)
# assign random ids to missing animal ids
ani_ids_na <- ani_ids == "anixxxx"
ani_ids[ani_ids_na] <- sample(1000:9999, size=sum(ani_ids_na), replace=F)
ani_ids[ani_ids_na] <- paste0("R", ani_ids[ani_ids_na])
data_info <- list(ani = ani_ids, gps = gps_units)
for(i in 1:length(data_files)) {
filestr <- gsub(paste0(dir_name,"(\\/)"), "", data_files[i])
site <- tolower(gsub("(\\_)(20)([0-9]{2}\\_)(.*\\_)(.*)(\\.csv)","", filestr))
df <- read.csv(data_files[i], skipNul = T)
aniid <- data_info$ani[i]
gpsid <- data_info$gps[i]
#on every 50th data file, increment file name counter and wipe data_sets
if(i %% 50 == 0 & i > 49) {
saveRDS(data_sets, rds_name)
num_saved_rds <- num_saved_rds + 1
rds_name <- paste0(data_dir, num_saved_rds, ".rds")
data_sets <- list()
}
# clean df
cleaned_df <- clean_df(df, aniid, gpsid)
# get meta from df
file_meta <- get_meta(df, i, data_files[i], site, aniid, rds_name)
# save meta to the designated meta df
meta_df <- save_meta(meta_df, file_meta)
# add cleaned df to the list of data
data_sets[[paste0("ani",aniid)]] <- cleaned_df
} #for loop
#save remaining data files
saveRDS(data_sets, rds_name)
return(meta_df)
}
clean_batch(list(name = "whatever", datapath = file.path(getwd(), "data/to_process.zip") ) )
clean_batch <- function(data_dir) {
#initialize empty meta
meta_df <- data.frame(matrix(ncol = 9, nrow = 0))
meta_cols <- c("file_id", "file_name", "site", "ani_id", "min_date", "max_date", "min_lat", "max_lat", "storage")
colnames(meta_df) <- meta_cols
unzip(data_dir$datapath, exdir="to_process")
data_files <- list.files("to_process", full.names = T)
# data_files <- paste0(getwd(), "/data/",  data_files$Name)
print(data_files)
data_sets <- list()
num_saved_rds <- 0
dir_name <- gsub(".zip", "", data_dir$name)
rds_name <- paste0(dir_name, ".rds")
gps_units <- gsub("(.*)(20)([0-9]{2}\\_)(.*)(\\_{1}.*)(\\.csv)","\\4",data_files)
ani_ids <- gsub("(.*)(20)([0-9]{2}\\_)(.*\\_)(.*)(\\.csv)","\\5",data_files)
# assign random ids to missing animal ids
ani_ids_na <- ani_ids == "anixxxx"
ani_ids[ani_ids_na] <- sample(1000:9999, size=sum(ani_ids_na), replace=F)
ani_ids[ani_ids_na] <- paste0("R", ani_ids[ani_ids_na])
data_info <- list(ani = ani_ids, gps = gps_units)
for(i in 1:length(data_files)) {
filestr <- gsub(paste0(dir_name,"(\\/)"), "", data_files[i])
site <- tolower(gsub("(\\_)(20)([0-9]{2}\\_)(.*\\_)(.*)(\\.csv)","", filestr))
df <- read.csv(data_files[i], skipNul = T)
aniid <- data_info$ani[i]
gpsid <- data_info$gps[i]
#on every 50th data file, increment file name counter and wipe data_sets
if(i %% 50 == 0 & i > 49) {
saveRDS(data_sets, rds_name)
num_saved_rds <- num_saved_rds + 1
rds_name <- paste0(data_dir, num_saved_rds, ".rds")
data_sets <- list()
}
# clean df
cleaned_df <- clean_df(df, aniid, gpsid)
# get meta from df
file_meta <- get_meta(df, i, data_files[i], site, aniid, rds_name)
# save meta to the designated meta df
meta_df <- save_meta(meta_df, file_meta)
# add cleaned df to the list of data
data_sets[[paste0("ani",aniid)]] <- cleaned_df
} #for loop
#save remaining data files
saveRDS(data_sets, rds_name)
return(meta_df)
}
clean_batch(list(name = "whatever", datapath = file.path(getwd(), "data/to_process.zip") ) )
devtools::build()
devtools::load_all()
clean_batch
unzip("data/to_process.zip")
unzip("data/to_process.zip", exdir="temp")
list.files(pattern=".csv", recursive = T)
list.files("temp", pattern=".csv", recursive = T, full.names=TRUE)
devtools::install_github("mathedjoe/animaltracker")
devtools::install_github("mathedjoe/animaltracker")
devtools::install_github("mathedjoe/animaltracker")
install.packages("shinycssloaders")
devtools::install_github("mathedjoe/animaltracker")
library("animaltracker")
devtools::install_github("mathedjoe/animaltracker")
library("animaltracker")
run_shiny_animaltracker()
packageVersion("scales")
run_shiny_animaltracker()
devtools::install_github("mathedjoe/animaltracker")
devtools::install_github("mathedjoe/animaltracker")
devtools::install_github("mathedjoe/animaltracker")
devtools::install_github("mathedjoe/animaltracker")
run_shiny_animaltracker()
devtools::install_github("mathedjoe/animaltracker")
library(animaltracker)
devtools::install_github("mathedjoe/animaltracker")
run_shiny_animaltracker()
devtools::github_install("mathedjoe/animaltracker")
devtools::install_github("mathedjoe/animaltracker"); library(animaltracker)
run_shiny_animaltracker()
get_elevation <- function(latmin, latmax, lonmin, lonmax, out_dir, zoom = 12, zone = 11) {
data_region <- sp::bbox(cbind(c(lonmin, lonmax), c(latmin,latmax))) # set a bounding box for retrieval of elev data
elev <- elevatr::get_aws_terrain( data_region, z=zoom, prj = "+proj=longlat") # retrieve high res elev data
elev2 <- raster::projectRaster(elev, crs = paste0("+proj=utm +zone=", zone, " ellps=WGS84") )
elevpts <- raster::rasterToPoints(elev2, spatial=TRUE) # convert to spatial pts
if(!dir.exists(out_dir)){
dir.create(out_dir, recursive = TRUE)
}
saveRDS(elevpts, file.path(out_dir, "elev_data.rds"))
return(elevpts)
}
get_elevation(latmin = 43.1,
#               latmax = 43.5,
#               lonmin = -117.6,
#               lonmax = -117,
#               out_dir = "data/elevation")
get_elevation(latmin = 43.1,
latmax = 43.5,
lonmin = -117.6,
lonmax = -117,
out_dir = "data/elevation")
)))
get_elevation(latmin = 43.1,
latmax = 43.5,
lonmin = -117.6,
lonmax = -117,
out_dir = "data/elevation")
?elevatr::get_aws_terrain
install.packages("elevatr")
install.packages("elevatr")
x<- data(demo)
str(x)
View(demo)
as.data.frame(x) %>% summary()
library(dplyr)
as.data.frame(x) %>% summary()
locations <- demo %>%
select(x = Longitude, y = Latitude)
get_elev_raster(locations, prj = "+proj=longlat", z=10)
elevatr::get_elev_raster(locations, prj = "+proj=longlat", z=10)
elev <- elevatr::get_elev_raster(locations, prj = "+proj=longlat", z=10)
plot(elev)
View(elev)
elevpts <- raster::rasterToPoints(elev, spatial=TRUE) # convert to spatial pts
plot(elevpts)
extract(elevpts)
str(elevpts$layer)
summary(elevpts$layer)
summary(demo$Altitude)
cor(elevpts$layer, demo$Altitude)
nrow(demo)
lookup_elevations <- function(anidf, zoom = 10) {
locations <- anidf %>%
select(x = Longitude, y = Latitude)
elev <- elevatr::get_elev_raster(locations, prj = "+proj=longlat", z=zoom)
elevpts <- raster::rasterToPoints(elev, spatial=TRUE) # convert to spatial pts
datapts <- rgdal::project(as.matrix(locations), crs(elevpts))
datapts <- as.data.frame(datapts)
datapts$alt <- anidf$Altitude
coordinates(datapts) <- ~x+y
datapts_elev <- nabor::knn(coordinates(elevpts), coordinates(datapts), k=1)
anidf$Elevation <- elevpts$layer[ datapts_elev$nn.idx]
return(anidf)
}
xelev <-lookup_elevations(demo)
?rgdal::project
datapts <- rgdal::project(as.matrix(locations), proj(elevpts))
proj(elevpts)
crs(elevpts)
?crs
projection(elevpts)
raster::projection(elevpts)
lookup_elevations <- function(anidf, zoom = 10) {
locations <- anidf %>%
select(x = Longitude, y = Latitude)
elev <- elevatr::get_elev_raster(locations, prj = "+proj=longlat", z=zoom)
elevpts <- raster::rasterToPoints(elev, spatial=TRUE) # convert to spatial pts
datapts <- rgdal::project(as.matrix(locations), raster::projection(elevpts))
datapts <- as.data.frame(datapts)
datapts$alt <- anidf$Altitude
coordinates(datapts) <- ~x+y
datapts_elev <- nabor::knn(coordinates(elevpts), coordinates(datapts), k=1)
anidf$Elevation <- elevpts$layer[ datapts_elev$nn.idx]
return(anidf)
}
xelev <-lookup_elevations(demo)
lookup_elevations <- function(anidf, zoom = 10) {
locations <- anidf %>%
select(x = Longitude, y = Latitude)
elev <- elevatr::get_elev_raster(locations, prj = "+proj=longlat", z=zoom)
elevpts <- raster::rasterToPoints(elev, spatial=TRUE) # convert to spatial pts
datapts <- rgdal::project(as.matrix(locations), raster::projection(elevpts))
datapts <- as.data.frame(datapts)
datapts$alt <- anidf$Altitude
raster::coordinates(datapts) <- ~x+y
datapts_elev <- nabor::knn(raster::coordinates(elevpts), raster::coordinates(datapts), k=1)
anidf$Elevation <- elevpts$layer[ datapts_elev$nn.idx]
return(anidf)
}
xelev <-lookup_elevations(demo)
?coordinates
lookup_elevations <- function(anidf, zoom = 10) {
locations <- anidf %>%
select(x = Longitude, y = Latitude)
elev <- elevatr::get_elev_raster(locations, prj = "+proj=longlat", z=zoom)
elevpts <- raster::rasterToPoints(elev, spatial=TRUE) # convert to spatial pts
datapts <- rgdal::project(as.matrix(locations), raster::projection(elevpts))
datapts <- as.data.frame(datapts)
datapts$alt <- anidf$Altitude
sp::coordinates(datapts) <- ~x+y
datapts_elev <- nabor::knn(sp::coordinates(elevpts), sp::coordinates(datapts), k=1)
anidf$Elevation <- elevpts$layer[ datapts_elev$nn.idx]
return(anidf)
}
xelev <-lookup_elevations(demo)
View(xelev)
xelev <-lookup_elevations(demo, zoom=12)
hist(xelev$Elevation)
summary(xelev$Elevation)
lookup_elevations <- function(anidf, zoom = 10) {
locations <- anidf %>%
select(x = Longitude, y = Latitude)
elev <- elevatr::get_elev_raster(locations, prj = "+proj=longlat", z=zoom)
elevpts <- raster::rasterToPoints(elev, spatial=TRUE) # convert to spatial pts
datapts <- rgdal::project(as.matrix(locations), raster::projection(elevpts))
datapts <- as.data.frame(datapts)
# datapts$alt <- anidf$Altitude
sp::coordinates(datapts) <- ~x+y
print(head(datapts))
datapts_elev <- nabor::knn(sp::coordinates(elevpts), sp::coordinates(datapts), k=1)
anidf$Elevation <- elevpts$layer[ datapts_elev$nn.idx]
return(anidf)
}
xelev <-lookup_elevations(demo, zoom=12)
nabor::knn
?nabor::knn
head(sp::coordinates(elevpts))
lookup_elevations <- function(anidf, zoom = 10) {
locations <- anidf %>%
select(x = Longitude, y = Latitude)
elev <- elevatr::get_elev_raster(locations, prj = "+proj=longlat", z=zoom)
elevpts <- raster::rasterToPoints(elev, spatial=TRUE) # convert to spatial pts
datapts_elev <- nabor::knn(elevpts, locations, k=1)
anidf$Elevation <- elevpts$layer[ datapts_elev$nn.idx]
return(anidf)
}
xelev <-lookup_elevations(demo, zoom=12)
head(sp::coordinates(elevpts))
ookup_elevations <- function(anidf, zoom = 10) {
locations <- anidf %>%
select(x = Longitude, y = Latitude)
elev <- elevatr::get_elev_raster(locations, prj = "+proj=longlat", z=zoom)
elevpts <- raster::rasterToPoints(elev, spatial=TRUE) # convert to spatial pts
datapts_elev <- nabor::knn(data = sp::coordinates(elevpts), query = locations, k=1)
anidf$Elevation <- elevpts$layer[ datapts_elev$nn.idx]
return(anidf)
}
xelev <-lookup_elevations(demo, zoom=12)
lookup_elevations <- function(anidf, zoom = 10) {
locations <- anidf %>%
select(x = Longitude, y = Latitude)
elev <- elevatr::get_elev_raster(locations, prj = "+proj=longlat", z=zoom)
elevpts <- raster::rasterToPoints(elev, spatial=TRUE) # convert to spatial pts
datapts_elev <- nabor::knn(data = sp::coordinates(elevpts), query = locations, k=1)
anidf$Elevation <- elevpts$layer[ datapts_elev$nn.idx]
return(anidf)
}
xelev <-lookup_elevations(demo, zoom=12)
hist(xelev$Elevation-xelev$Altitude)
psych::describe(xelev$Elevation-xelev$Altitude)
hist(xelev$Elevation)
hist(xelev$Altitude)
plot(xelev$Altitude, xelev$Elevation)
xelev <- lookup_elevations(demo, zoom = 12)
histogram_animal_elevation <- function(datapts) {
histogram <- ggplot(datapts, aes(x = Elevation - Altitude)) +
xlim(-100,100)+
geom_histogram(aes(y=..density..), colour="blue", fill="lightblue", binwidth = 2 )+
geom_density(alpha=.2, fill="#FF6666") +
geom_vline(aes(xintercept = mean((Elevation-Altitude)[abs(Elevation-Altitude) <= 100])),col='blue',size=2)+
labs(title = "Distribution of Modeled Elevation - Measured Altitude (meters)")+
theme_minimal()
return(histogram)
}
histogram_animal_elevation(xelev)
histogram_animal_elevation <- function(datapts) {
histogram <- ggplot2::ggplot(datapts, aes(x = Elevation - Altitude)) +
xlim(-100,100)+
geom_histogram(aes(y=..density..), colour="blue", fill="lightblue", binwidth = 2 )+
geom_density(alpha=.2, fill="#FF6666") +
geom_vline(aes(xintercept = mean((Elevation-Altitude)[abs(Elevation-Altitude) <= 100])),col='blue',size=2)+
labs(title = "Distribution of Modeled Elevation - Measured Altitude (meters)")+
theme_minimal()
return(histogram)
}
histogram_animal_elevation(xelev)
histogram_animal_elevation <- function(datapts) {
require(ggplot2)
histogram <- ggplot(datapts, aes(x = Elevation - Altitude)) +
xlim(-100,100)+
geom_histogram(aes(y=..density..), colour="blue", fill="lightblue", binwidth = 2 )+
geom_density(alpha=.2, fill="#FF6666") +
geom_vline(aes(xintercept = mean((Elevation-Altitude)[abs(Elevation-Altitude) <= 100])),col='blue',size=2)+
labs(title = "Distribution of Modeled Elevation - Measured Altitude (meters)")+
theme_minimal()
return(histogram)
}
histogram_animal_elevation(xelev)
xelev <- lookup_elevations(demo, zoom = 10)
histogram_animal_elevation(xelev)
devtools::install_github("mathedjoe/animaltracker"); library(animaltracker);
devtools::build()
devtools::load()
devtools::load_all()
devtools::build(manual=TRUE)
devtools::build(manual=TRUE, binary=TRUE)
devtools::build(binary= TRUE, manual=TRUE)
devtools::load_all()
run_shiny_animaltracker()
devtools::load_all()
run_shiny_animaltracker()
devtools::load_all()
run_shiny_animaltracker()
devtools::load_all()
run_shiny_animaltracker()
clean_df <- function(df, ani_id, gps_id) {
timezone <- "UTC"
window <- list(latmax = 43.3464, lonmin = -117.2305, latmin = 43.2472, lonmax=-117.101 )
nstart <- nrow(df)
### REMOVE BAD DATA POINTS (as described on pages 26-39 of Word Doc)
df<- df %>%
tibble::add_column(Order = df$Index, .before="Index")%>%  # add Order column
tibble::add_column(Animal = ani_id, .after="Index") %>%      # add Animal column
tibble::add_column(GPS = gps_id, .after="Animal") %>%      # add Animal column
tibble::add_column(DateTime = NA, .after="GPS") %>%      # add Date/Time column
tibble::add_column(TimeDiff = NA, .after="DateTime") %>%
tibble::add_column(TimeDiffMins = NA, .after="TimeDiff") %>%
tibble::add_column(Rate = NA, .after="Distance") %>%
tibble::add_column(CourseDiff = NA, .after="Course") %>%
dplyr::mutate(Animal = as.factor(Animal))  %>%                     # reclassify Animal column as a categorical (factor) variable
dplyr::mutate(DateTime = as.POSIXct(paste(Date, Time), "%Y/%m/%d %H:%M:%S", tz=timezone)) %>%  # reclassify Date as a Date variable
dplyr::mutate(Date = as.Date(Date, "%Y/%m/%d"))  %>%            # reclassify Date as a Date variable
dplyr::mutate(TimeDiff = as.numeric(DateTime - dplyr::lag(DateTime,1))) %>%  # compute sequential time differences (in seconds)
dplyr::mutate(TimeDiffMins = as.numeric(difftime(DateTime,dplyr::lag(DateTime,1), units="mins")))  %>% # compute sequential time differences (in mins)
dplyr::mutate(Rate = Distance/TimeDiffMins) %>% # compute rate of travel (meters/min)
dplyr::mutate(CourseDiff = abs(Course - dplyr::lag(Course,1))) %>%
dplyr::mutate(DistGeo = geosphere::distGeo(cbind(Longitude, Latitude),
cbind(dplyr::lag(Longitude,1), dplyr::lag(Latitude, 1))
) ) %>% #compute geodesic distance between points
dplyr::mutate(RateFlag = 1*(Rate > 84)) %>%  # flag any data points representing too fast travel
dplyr::mutate(CourseFlag = 1*(CourseDiff >= 100) ) %>%
dplyr::mutate(DistanceFlag = 1*(DistGeo >= 840 )) %>%
dplyr::mutate(TotalFlags = RateFlag + CourseFlag + DistanceFlag) %>%
dplyr::filter(!is.na(DateTime), TotalFlags < 2,
Latitude!=0, Longitude !=0,
TimeDiffMins < 100,
Altitude > 2700/3.3, Altitude< 6000/3.3, # lower and upper limits (converted from feet to meters)
Latitude >= window$latmin,  Latitude <= window$latmax,
Longitude >= window$lonmin,  Longitude <= window$lonmax,
!DistanceFlag )
# add elevation data
df <- lookup_elevation()
return(df)
}
